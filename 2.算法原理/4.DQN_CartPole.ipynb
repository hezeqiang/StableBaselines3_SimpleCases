{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.03653317, -0.00187937, -0.02338587,  0.00402136], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "\n",
    "#定义环境\n",
    "class MyWrapper(gym.Wrapper):\n",
    "\n",
    "    def __init__(self):\n",
    "        env = gym.make('CartPole-v1', render_mode='rgb_array')\n",
    "        super().__init__(env)\n",
    "        self.env = env\n",
    "        self.step_n = 0\n",
    "\n",
    "    def reset(self,**kwargs):\n",
    "        self.step_n = 0\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        #一局游戏最多走N步\n",
    "        self.step_n += 1\n",
    "        if self.step_n >= 200:\n",
    "            terminated = True\n",
    "\n",
    "        return state, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "env = MyWrapper()\n",
    "\n",
    "env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#打印游戏\n",
    "def show():\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(env.render())\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.observation_space= Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "env.action_space= Discrete(2)\n",
      "state= [-0.01347326 -0.00353876 -0.04355745  0.02381279]\n",
      "action= 1\n",
      "next_state= [-0.01354404  0.1921799  -0.04308119 -0.28228858]\n",
      "reward= 1.0\n",
      "done= False\n",
      "probs= {}\n"
     ]
    }
   ],
   "source": [
    "#认识游戏环境\n",
    "def test_env():\n",
    "    print('env.observation_space=', env.observation_space)\n",
    "    print('env.action_space=', env.action_space)\n",
    "\n",
    "    state, probs = env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info  = env.step(action)\n",
    "\n",
    "    print('state=', state)\n",
    "    print('action=', action)\n",
    "    print('next_state=', next_state)\n",
    "    print('reward=', reward)\n",
    "    print('done=', terminated)\n",
    "    print('probs=',probs)\n",
    "\n",
    "\n",
    "test_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13306\\anaconda3\\envs\\SB3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=128, out_features=2, bias=True)\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=4, out_features=128, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=128, out_features=2, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#计算动作的模型,也是真正要用的模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    ").to(device)\n",
    "\n",
    "#经验网络,用于评估一个状态的分数\n",
    "target_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4, 128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128, 2),\n",
    ").to(device)\n",
    "\n",
    "#把model的参数复制给next_model\n",
    "target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "model, target_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#得到一个动作\n",
    "def get_action(state):\n",
    "    if random.random() < 0.01:\n",
    "        return random.choice([0, 1])\n",
    "\n",
    "    #走神经网络,得到一个动作\n",
    "    state = torch.FloatTensor(state).reshape(1, 4).to(device) #batch_size, state_size\n",
    "\n",
    "    #print(model(state))\n",
    "    #print(model(state).argmax())\n",
    "    #print(model(state).argmax().item()) # o or 1, indicates the best action\n",
    "\n",
    "    return model(state).argmax().item() # forward, return the max q and the action\n",
    "\n",
    "\n",
    "get_action([0.0013847, -0.01194451, 0.04260966, 0.00688801])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 CUDA buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#制造样本池。 这里没有用到cuda，所以不使用了\n",
    "datas = []\n",
    "\n",
    "\n",
    "#向样本池中添加N条数据,删除M条最古老的数据\n",
    "def update_data():\n",
    "    old_count = len(datas)\n",
    "\n",
    "    #玩到新增了N个数据为止\n",
    "    while len(datas) - old_count < 199:\n",
    "        #初始化游戏\n",
    "        state, _ = env.reset()\n",
    "        # print(state)\n",
    "\n",
    "        #玩到游戏结束为止\n",
    "        terminated = False\n",
    "        while not terminated:\n",
    "            #根据当前状态得到一个动作\n",
    "            action = get_action(state)\n",
    "\n",
    "\n",
    "            #执行动作,得到反馈\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "            # print(next_state, reward, terminated, truncated, info )\n",
    "\n",
    "            #记录数据样本\n",
    "            datas.append((state, action, reward, next_state, terminated))\n",
    "\n",
    "            #更新游戏状态,开始下一个动作\n",
    "            state = next_state\n",
    "\n",
    "    #数据上限,超出时从最古老的开始删除\n",
    "    while len(datas) > 1_0000:\n",
    "        datas.pop(0)\n",
    "\n",
    "\n",
    "update_data()\n",
    "len(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13306\\AppData\\Local\\Temp\\ipykernel_60336\\3070215748.py:7: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 4).to(device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 4]),\n",
       " tensor([[0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "          1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]], device='cuda:0'),\n",
       " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]], device='cuda:0'),\n",
       " torch.Size([64, 4]),\n",
       " tensor([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取一批数据样本\n",
    "def get_sample():\n",
    "    #从样本池中64个采样\n",
    "    samples = random.sample(datas, 64)\n",
    "\n",
    "    #[b, 4]\n",
    "    state = torch.FloatTensor([i[0] for i in samples]).reshape(-1, 4).to(device)\n",
    "    #[b, 1]\n",
    "    action = torch.LongTensor([i[1] for i in samples]).reshape(-1, 1).to(device)\n",
    "    #[b, 1]\n",
    "    reward = torch.FloatTensor([i[2] for i in samples]).reshape(-1, 1).to(device)\n",
    "    #[b, 4]\n",
    "    next_state = torch.FloatTensor([i[3] for i in samples]).reshape(-1, 4).to(device)\n",
    "    #[b, 1]\n",
    "    over = torch.LongTensor([i[4] for i in samples]).reshape(-1, 1).to(device)\n",
    "\n",
    "    return state, action, reward, next_state, over\n",
    "\n",
    "\n",
    "state, action, reward, next_state, over = get_sample()\n",
    "\n",
    "state.size(), action.reshape(1,-1), reward.reshape(1,-1), next_state.size(), over.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0385],\n",
       "        [0.0750],\n",
       "        [0.0379],\n",
       "        [0.1247],\n",
       "        [0.0277],\n",
       "        [0.0720],\n",
       "        [0.0932],\n",
       "        [0.1174],\n",
       "        [0.0302],\n",
       "        [0.0313],\n",
       "        [0.1478],\n",
       "        [0.0341],\n",
       "        [0.1269],\n",
       "        [0.0319],\n",
       "        [0.0401],\n",
       "        [0.0362],\n",
       "        [0.0794],\n",
       "        [0.0622],\n",
       "        [0.0360],\n",
       "        [0.1329],\n",
       "        [0.0318],\n",
       "        [0.0383],\n",
       "        [0.0312],\n",
       "        [0.0382],\n",
       "        [0.0895],\n",
       "        [0.0296],\n",
       "        [0.0896],\n",
       "        [0.0333],\n",
       "        [0.0625],\n",
       "        [0.0368],\n",
       "        [0.0552],\n",
       "        [0.0779],\n",
       "        [0.0353],\n",
       "        [0.0526],\n",
       "        [0.0331],\n",
       "        [0.0252],\n",
       "        [0.0311],\n",
       "        [0.0380],\n",
       "        [0.0404],\n",
       "        [0.0364],\n",
       "        [0.0406],\n",
       "        [0.0307],\n",
       "        [0.0371],\n",
       "        [0.0858],\n",
       "        [0.0988],\n",
       "        [0.1372],\n",
       "        [0.0416],\n",
       "        [0.1116],\n",
       "        [0.0281],\n",
       "        [0.0400],\n",
       "        [0.0651],\n",
       "        [0.0334],\n",
       "        [0.0366],\n",
       "        [0.0490],\n",
       "        [0.0583],\n",
       "        [0.0833],\n",
       "        [0.0291],\n",
       "        [0.0657],\n",
       "        [0.0324],\n",
       "        [0.0409],\n",
       "        [0.0473],\n",
       "        [0.1204],\n",
       "        [0.0949],\n",
       "        [0.0383]], device='cuda:0', grad_fn=<GatherBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_qvalue(state, action):\n",
    "    #使用状态计算出动作的logits\n",
    "    #[b, 4] -> [b, 2]\n",
    "    # print(state, action)\n",
    "    value = model(state) # action is already obtained by forward calculation via model(state).argmax().item()\n",
    "    # print(value)\n",
    "\n",
    "    #根据实际使用的action取出每一个值\n",
    "    #这个值就是模型评估的在该状态下,执行动作的分数\n",
    "    #在执行动作前,显然并不知道会得到的反馈和next_state\n",
    "    #所以这里不能也不需要考虑next_state和reward\n",
    "    #[b, 2] -> [b, 1]\n",
    "    value = value.gather(dim=1, index=action) # the action is the best one in current state\n",
    "    # print(value) # best q\n",
    "\n",
    "    return value # q value\n",
    "\n",
    "\n",
    "get_qvalue(state, action) # 64 samples, action space 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.3020, 27.3173],\n",
      "        [49.3474, 49.1575],\n",
      "        [15.1400, 21.8596],\n",
      "        [43.1486, 45.7153],\n",
      "        [44.5409, 47.4569],\n",
      "        [38.6912, 41.8864],\n",
      "        [38.2400, 41.8224],\n",
      "        [26.8617, 32.1503],\n",
      "        [43.4888, 45.2425],\n",
      "        [35.4382, 40.0791],\n",
      "        [28.0833, 33.5425],\n",
      "        [32.6366, 38.3292],\n",
      "        [33.3827, 38.1785],\n",
      "        [25.7422, 31.8381],\n",
      "        [47.5144, 49.3074],\n",
      "        [42.4028, 45.3046],\n",
      "        [49.0607, 49.5487],\n",
      "        [40.7599, 43.3117],\n",
      "        [14.9178, 21.7229],\n",
      "        [15.1952, 21.2612],\n",
      "        [39.0250, 42.7838],\n",
      "        [44.9190, 47.1404],\n",
      "        [47.4434, 48.5534],\n",
      "        [44.2308, 46.3658],\n",
      "        [22.1296, 27.3422],\n",
      "        [46.6276, 47.8598],\n",
      "        [37.5428, 41.1468],\n",
      "        [37.8998, 41.9264],\n",
      "        [23.7313, 28.4206],\n",
      "        [16.0343, 22.9589],\n",
      "        [46.7782, 48.2425],\n",
      "        [22.2966, 27.4004],\n",
      "        [35.6870, 40.1811],\n",
      "        [28.1739, 32.6828],\n",
      "        [31.8566, 37.2615],\n",
      "        [47.9610, 49.5237],\n",
      "        [23.5533, 29.8602],\n",
      "        [49.5489, 49.5359],\n",
      "        [45.8443, 48.2057],\n",
      "        [15.3020, 22.1743],\n",
      "        [30.8511, 35.0147],\n",
      "        [31.1439, 36.6490],\n",
      "        [45.7056, 47.1605],\n",
      "        [49.2201, 48.9860],\n",
      "        [23.2396, 28.5401],\n",
      "        [39.0706, 42.6862],\n",
      "        [45.6427, 47.1505],\n",
      "        [30.4590, 35.3494],\n",
      "        [48.6560, 49.2131],\n",
      "        [46.5510, 48.4222],\n",
      "        [44.9982, 46.8467],\n",
      "        [32.6694, 37.6145],\n",
      "        [44.7619, 46.9705],\n",
      "        [43.4926, 45.3267],\n",
      "        [28.6045, 33.1612],\n",
      "        [33.7560, 37.7423],\n",
      "        [49.1177, 49.6571],\n",
      "        [37.6224, 40.7119],\n",
      "        [29.6315, 35.2958],\n",
      "        [47.7461, 49.2257],\n",
      "        [40.3809, 42.9163],\n",
      "        [45.5844, 47.5126],\n",
      "        [32.1469, 36.6871],\n",
      "        [22.4511, 28.5730]], device='cuda:0')\n",
      "torch.return_types.max(\n",
      "values=tensor([27.3173, 49.3474, 21.8596, 45.7153, 47.4569, 41.8864, 41.8224, 32.1503,\n",
      "        45.2425, 40.0791, 33.5425, 38.3292, 38.1785, 31.8381, 49.3074, 45.3046,\n",
      "        49.5487, 43.3117, 21.7229, 21.2612, 42.7838, 47.1404, 48.5534, 46.3658,\n",
      "        27.3422, 47.8598, 41.1468, 41.9264, 28.4206, 22.9589, 48.2425, 27.4004,\n",
      "        40.1811, 32.6828, 37.2615, 49.5237, 29.8602, 49.5489, 48.2057, 22.1743,\n",
      "        35.0147, 36.6490, 47.1605, 49.2201, 28.5401, 42.6862, 47.1505, 35.3494,\n",
      "        49.2131, 48.4222, 46.8467, 37.6145, 46.9705, 45.3267, 33.1612, 37.7423,\n",
      "        49.6571, 40.7119, 35.2958, 49.2257, 42.9163, 47.5126, 36.6871, 28.5730],\n",
      "       device='cuda:0'),\n",
      "indices=tensor([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')) tensor([27.3173, 49.3474, 21.8596, 45.7153, 47.4569, 41.8864, 41.8224, 32.1503,\n",
      "        45.2425, 40.0791, 33.5425, 38.3292, 38.1785, 31.8381, 49.3074, 45.3046,\n",
      "        49.5487, 43.3117, 21.7229, 21.2612, 42.7838, 47.1404, 48.5534, 46.3658,\n",
      "        27.3422, 47.8598, 41.1468, 41.9264, 28.4206, 22.9589, 48.2425, 27.4004,\n",
      "        40.1811, 32.6828, 37.2615, 49.5237, 29.8602, 49.5489, 48.2057, 22.1743,\n",
      "        35.0147, 36.6490, 47.1605, 49.2201, 28.5401, 42.6862, 47.1505, 35.3494,\n",
      "        49.2131, 48.4222, 46.8467, 37.6145, 46.9705, 45.3267, 33.1612, 37.7423,\n",
      "        49.6571, 40.7119, 35.2958, 49.2257, 42.9163, 47.5126, 36.6871, 28.5730],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[27.7710],\n",
       "        [49.3605],\n",
       "        [ 1.0000],\n",
       "        [45.8010],\n",
       "        [47.5078],\n",
       "        [42.0487],\n",
       "        [41.9860],\n",
       "        [32.5073],\n",
       "        [45.3377],\n",
       "        [40.2775],\n",
       "        [33.8716],\n",
       "        [38.5626],\n",
       "        [38.4150],\n",
       "        [32.2014],\n",
       "        [49.3212],\n",
       "        [45.3985],\n",
       "        [49.5577],\n",
       "        [43.4455],\n",
       "        [22.2885],\n",
       "        [ 1.0000],\n",
       "        [42.9281],\n",
       "        [47.1976],\n",
       "        [48.5823],\n",
       "        [46.4385],\n",
       "        [27.7954],\n",
       "        [47.9026],\n",
       "        [41.3238],\n",
       "        [42.0879],\n",
       "        [28.8522],\n",
       "        [23.4998],\n",
       "        [48.2777],\n",
       "        [27.8524],\n",
       "        [40.3775],\n",
       "        [33.0291],\n",
       "        [37.5162],\n",
       "        [49.5332],\n",
       "        [30.2630],\n",
       "        [49.5580],\n",
       "        [48.2416],\n",
       "        [22.7308],\n",
       "        [35.3144],\n",
       "        [36.9160],\n",
       "        [47.2173],\n",
       "        [49.2357],\n",
       "        [28.9693],\n",
       "        [42.8325],\n",
       "        [47.2075],\n",
       "        [35.6424],\n",
       "        [49.2288],\n",
       "        [48.4537],\n",
       "        [46.9098],\n",
       "        [37.8622],\n",
       "        [47.0311],\n",
       "        [45.4202],\n",
       "        [33.4980],\n",
       "        [37.9875],\n",
       "        [49.6639],\n",
       "        [40.8977],\n",
       "        [35.5899],\n",
       "        [49.2412],\n",
       "        [43.0580],\n",
       "        [47.5624],\n",
       "        [36.9533],\n",
       "        [29.0016]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target(reward, next_state, over):\n",
    "    #上面已经把模型认为的状态下执行动作的分数给评估出来了, i.e., q value\n",
    "    #下面使用next_state和reward计算真实的分数\n",
    "    #针对一个状态,它到底应该多少分,可以使用以往模型积累的经验评估\n",
    "    #这也是没办法的办法,因为显然没有精确解,这里使用延迟更新的next_model评估\n",
    "\n",
    "    #使用next_state计算下一个状态的分数\n",
    "    #[b, 4] -> [b, 2]\n",
    "    with torch.no_grad():\n",
    "        target = target_model(next_state) # return the q value and action\n",
    "    #print(target)\n",
    "    #取所有动作中分数最大的\n",
    "    #[b, 2] -> [b, 1]\n",
    "    #print(target.max(dim=1),target.max(dim=1)[0])\n",
    "    target = target.max(dim=1)[0] # the max q value\n",
    "    target_next_action = target.max(dim=1)[1] # the max q value\n",
    "    target = target.reshape(-1, 1) # (64, 1) batch_size:64\n",
    "\n",
    "    #下一个状态的分数乘以一个系数,相当于权重\n",
    "    target *= 0.98\n",
    "\n",
    "    #如果next_state已经游戏结束,则next_state的分数是0\n",
    "    #因为如果下一步已经游戏结束,显然不需要再继续玩下去,也就不需要考虑next_state了.\n",
    "    #[b, 1] * [b, 1] -> [b, 1]\n",
    "    target *= (1 - over)\n",
    "\n",
    "    #加上reward就是最终的分数\n",
    "    #[b, 1] + [b, 1] -> [b, 1]\n",
    "    target += reward\n",
    "\n",
    "    return target\n",
    "\n",
    "\n",
    "get_target(reward, next_state, over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython import display\n",
    "\n",
    "\n",
    "def test(play=False):\n",
    "    state,_ = env.reset()\n",
    "    reward_sum = 0\n",
    "    terminated = False\n",
    "    while not terminated:\n",
    "        action = get_action(state)\n",
    "        state, reward, terminated, truncated, info  = env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "        if play and random.random() < 0.2:  #跳帧\n",
    "            display.clear_output(wait=True)\n",
    "            show()\n",
    "\n",
    "    return reward_sum\n",
    "\n",
    "\n",
    "sum([test() for _ in range(20)]) / 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OHoSU6uI-xIt",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 429 9.8\n",
      "50 10000 138.8\n",
      "100 10000 161.4\n",
      "150 10000 196.4\n",
      "200 10000 200.0\n",
      "250 10000 172.0\n",
      "300 10000 184.4\n",
      "350 10000 188.0\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    #训练N次\n",
    "    for epoch in range(400):\n",
    "        #更新N条数据\n",
    "        update_data()\n",
    "\n",
    "        #每次更新过数据后,每次64个sample,学习100次\n",
    "        for i in range(100):\n",
    "            #采样一批数据\n",
    "            state, action, reward, next_state, over = get_sample() # 64个sample\n",
    "\n",
    "            #计算一批样本的value和target\n",
    "            value = get_qvalue(state, action)\n",
    "            target = get_target(reward, next_state, over)\n",
    "\n",
    "            #更新参数\n",
    "            loss = loss_fn(value, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #把model的参数复制给next_model every 10 steps\n",
    "            if (i + 1) % 10 == 0:\n",
    "                target_model.load_state_dict(model.state_dict())\n",
    "\n",
    "        if epoch % 50 == 0:\n",
    "            print(epoch, len(datas), sum([test() for _ in range(5)]) / 5)\n",
    "\n",
    "    torch.save(model, 'save/4.DQN_CartPole')\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('save/4.DQN_CartPole')\n",
    "\n",
    "test(play=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "第7章-DQN算法.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
